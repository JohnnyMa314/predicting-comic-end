{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 短命作品の学習と予測\n",
    "\n",
    "　目次情報を学習して，短命作品を予測してみます．\n",
    "\n",
    "## 環境構築\n",
    "\n",
    "```bash\n",
    "conda env create -f env.yml\n",
    "```\n",
    "\n",
    "## 問題設定\n",
    "\n",
    "　本記事の目的は，2週目から7週目までの掲載順を入力とし，当該作品が短命作品（10週以内に終了する作品）か否かを予測することです．1週目の掲載順を除外したのは，新連載作品はほとんど巻頭に掲載されるためです．また，近年最短とされる作品が8週連載なので，遅くともこの1週間前には打ち切りを予測するため，7週目までの掲載順を入力としました．打ち切りを阻止するためには，もっと早期に打ち切りを予測する必要がありますが，これは今後の課題ということで…．\n",
    "\n",
    "## 目次データ\n",
    "\n",
    "　[0_obtain_comic_data_j.ipynb](0_obtain_comic_data_j.ipynb)で取得した`data/wj-api.json`を使います．また，[1_analyze_comic_data_j.ipynb](1_analyze_comic_data_j.ipynb)で定義した`ComicAnalyzer`を`analyze.py`からimportして使います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import analize\n",
    "\n",
    "wj = analize.ComicAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル\n",
    "\n",
    "　以下に，本記事で想定する[多層パーセプトロン](https://en.wikipedia.org/wiki/Multilayer_perceptron)のモデルを示します．多層パーセプトロンについては，[誤差逆伝播法のノート](http://qiita.com/Ugo-Nama/items/04814a13c9ea84978a4c)が詳しいです．\n",
    "\n",
    "![model.png](fig/model.png)\n",
    "\n",
    "　本記事では，隠れ層1層の多層パーセプトロンを用います．入力層は6ノード（2週目から7週目までの掲載順），隠れ層は$n$ノード，出力層は1ノード（短命作品である確率）を含みます．隠れ層および出力層の活性化関数として，[Sigmoid関数](https://ja.wikipedia.org/wiki/%E6%B4%BB%E6%80%A7%E5%8C%96%E9%96%A2%E6%95%B0#.E3.82.B7.E3.82.B0.E3.83.A2.E3.82.A4.E3.83.89.E9.96.A2.E6.95.B0)を用います．学習率として，$r$を用います．最適化アルゴリズムとして，オーソドックスな[Stochastic Gradient Descent (SGD)](https://ja.wikipedia.org/wiki/%E7%A2%BA%E7%8E%87%E7%9A%84%E5%8B%BE%E9%85%8D%E9%99%8D%E4%B8%8B%E6%B3%95#cite_note-17)と，人気の[Adam](https://arxiv.org/abs/1412.6980)の両方を使って結果を比較します．\n",
    " \n",
    "　本記事では，以下のハイパーパラメータを調整して，予測性能の最大化を目指します．\n",
    "\n",
    "|項目|設計空間|補足|\n",
    "|:--|:--|:--|\n",
    "|学習率（$r$）| $0 < r < 1$| 大きいほど収束が速いが，大きすぎるとうまく学習しない．|\n",
    "|隠れ層のノード数（$n$）| $\\{1, 2,...,8\\}$ |最大でも入力層＋出力層が目安？|\n",
    "|最適化アルゴリズム| {Gradient descent, Adam}| 前者はオーソドックス，Adamは新しめ．|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 学習データ，テストデータの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_x(anlzr, title='ONE PIECE'):\n",
    "    worsts = np.array(anlzr.extract_item(title)[1:7])\n",
    "    bests = np.array(anlzr.extract_item(title, 'best')[1:7])\n",
    "    worsts_normalized = worsts / (worsts + bests - 1)    \n",
    "    return worsts_normalized\n",
    "\n",
    "\n",
    "def make_y(anlzr, title='ONE PIECE', thresh_week=10):\n",
    "    return float(len(anlzr.extract_item(title)) <=  thresh_week)\n",
    "\n",
    "\n",
    "def batch_x_y(anlzr, titles, thresh_week=10):\n",
    "    xs = np.array([make_x(anlzr, title) for title in titles])\n",
    "    ys = np.array([make_y(anlzr, title, thresh_week) for title in titles])\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x, test_y = batch_x_y(wj, wj.end_titles[-100:])\n",
    "train_x, train_y = batch_x_y(wj, wj.end_titles[:-100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多層パーセプトロンの構築\n",
    "\n",
    "　`ComicNet()`は，多層パーセプトロンを管理するクラスです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class ComicNet():\n",
    "    def __init__(self, train_x, train_y, test_x, test_y,\n",
    "                 r=0.01, n=4, epoch=1000, algo='GD'):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.test_x = test_x\n",
    "        self.test_y = test_y\n",
    "        self.learning_rate = r\n",
    "        self.n_hidden = n\n",
    "        self.epoch = epoch\n",
    "        self.algo = algo\n",
    "                \n",
    "    def build_network(self):\n",
    "        n_input = self.test_x.shape[1]\n",
    "        n_output = self.test_y.shape[0]\n",
    "        x = tf.placeholder(tf.float32, [None, n_input], name='x')\n",
    "        y = tf.placeholder(tf.float32, [None, n_output], name='y')\n",
    "        \n",
    "        w_hidden = tf.Variable(\n",
    "            tf.truncated_normal((n_input, self.n_hidden), stddev=0.01))\n",
    "        b_hidden = tf.Variable(tf.zeros(self.n_hidden))\n",
    "        layer = tf.add(tf.matmul(x, w_hidden), b_hidden)\n",
    "        layer = tf.nn.sigmoid(layer)\n",
    "        \n",
    "        w_output = tf.Variable(\n",
    "            tf.truncated_normal((self.n_hidden, n_output), stddev=0.01))\n",
    "        b_output = tf.Variable(tf.zeros(n_output))\n",
    "        layer = tf.add(tf.matmul(layer, w_output), b_output)\n",
    "        layer = tf.nn.sigmoid(layer)\n",
    "        \n",
    "        cost = tf.nn.l2_loss(y - layer)\n",
    "        \n",
    "        if self.algo == 'GD':\n",
    "            optimizer = tf.train.GradientDescentOptimizer(\n",
    "                self.learning_rate).minimize(cost)\n",
    "        else:\n",
    "            optimizer = tf.train.AdamOptimizer(\n",
    "                self.learning_rate).minimize(cost)\n",
    "        \n",
    "        accuracy = tf.reduce_mean(y - layer, name='accuracy')\n",
    "\n",
    "    \n",
    "    def print_stats(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def test(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "wjnet = ComicNet(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "wjnet.build_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
